# Configuration settings for the Mycroft AI Assistant

# Specify the local model you want to use from Ollama.
# Make sure you have pulled this model with `ollama pull <model_name>`
MODEL_NAME = "llama3.1:8b"